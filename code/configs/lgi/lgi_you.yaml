# activity, tacos
max_num_words : 20
max_num_nodes : 20
max_num_frames : 200 # 200 for charades, 64
d_model : 512
num_heads : 4
batch_size : 64
dropout : 0.2
word_dim : 300
frame_dim : 500
num_gcn_layers : 2 
num_attn_layers : 2
iou : [0.1, 0.3, 0.5, 0.7]
is_adj : False
with_max_IoU : 0.3
vocab_size : 1493 # act: 8000, char: 1111, did: 6250, msr: 11901, tac: 1352, tvr: 9592, you: 1493

model_config:
  model_type: "LGI"
  resume: False 
  checkpoint_path: ""
  use_gpu: True
  ### Video Encoder
  use_video_encoder: False
  video_enc_vemb_idim: 512
  video_enc_vemb_odim: 512 # (=vdim)
  video_enc_use_position: True
  video_enc_pemb_idim: 512
  video_enc_pemb_odim: 512
  ### Query Encoder
  query_enc_emb_idim: 2199 # == vocabulary size
  query_enc_emb_odim: 300 # == dim of Glove
  query_enc_rnn_type: "LSTM"
  query_enc_rnn_bidirectional: True
  query_enc_rnn_nlayer: 2
  query_enc_rnn_idim: 300 # == query_emb_odim
  query_enc_rnn_hdim: 256 # (=qdim)
  query_enc_rnn_dropout: 0.5
  glove_path: ""
  ### Sequential Query Attention Network (SQAN)
  num_semantic_entity: 3
  sqan_qdim: 512 # == qdim 
  sqan_att_cand_dim: 512 # == qdim
  sqan_att_key_dim: 512 # == qdim
  sqan_att_hdim: 256
  sqan_att_drop_prob: 0.0
  ### Local-Global Video-Text interactions (LGI)
  lgi_fusion_method: "mul"
  lgi_hp_idim_1: 512 # == qdim
  lgi_hp_idim_2: 512 # == qdim
  lgi_hp_hdim: 512 # == vdim
  lgi_local_type: "res_block"
  lgi_local_res_block_1d_idim: 512 # == vdim
  lgi_local_res_block_1d_odim: 512 # == vdim
  lgi_local_res_block_1d_hdim: 256
  lgi_local_res_block_1d_ksize: 15
  lgi_local_num_res_blocks: 1
  lgi_local_do_downsample: False
  lgi_global_type: "nl"
  lgi_global_satt_att_n: 1
  lgi_global_satt_att_cand_dim: 512 # == vdim
  lgi_global_satt_att_hdim: 256
  lgi_global_satt_att_use_embedding: True
  lgi_global_satt_att_edim: 512
  lgi_global_num_nl_block: 2
  lgi_global_nl_idim: 512 # == vdim
  lgi_global_nl_odim: 512
  lgi_global_nl_nheads: 4
  lgi_global_nl_use_bias: True
  lgi_global_nl_drop_prob: 0.0
  lgi_global_nl_use_local_mask: False
  ### Temporal Attention based Regression
  grounding_att_key_dim: 512
  grounding_att_cand_dim: 512
  grounding_att_hdim: 256
  grounding_att_drop_prob: 0.0
  grounding_idim: 512
  grounding_hdim: 512
  ### Criterion
  use_temporal_attention_guidance_loss: false
  tag_weight: 1.0
  use_distinct_query_attention_loss: True
  dqa_weight: 1.0
  dqa_lambda: 0.3
train_loader:
  dataset: "youcook2"
  split: "train"
  # in_memory: True
  in_memory: False
  batch_size: 100
  data_dir: "data/youcook2"
  feature_type: "MIL-NCE"
  video_feature_path: "/data/projects/VT_localization/tsgv_data/data/youcook2/coot{}.npy"
  annotation_path: "/data/projects/VT_localization/tsgv_data/data/youcook2/train_data.json"
  max_length: 10
  word_frequency_threshold: 1
  num_segment: 128
test_loader:
  dataset: "youcook2"
  split: "test"
  # in_memory: True
  in_memory: False
  batch_size: 100
  data_dir: "data/youcook2"
  feature_type: "MIL-NCE"
  video_feature_path: "/data/projects/VT_localization/tsgv_data/data/youcook2/coot/{}.npy"
  annotation_path: "/data/projects/VT_localization/tsgv_data/data/youcook2/test_data.json"
  # - "/data/projects/VT_localization/tsgv_data/data/youcook2/val_data.json"
  max_length: 10
  word_frequency_threshold: 1
  num_segment: 128
optimize:
  num_step: 500 # epoch
  optimizer_type: "Adam"
  init_lr: 0.0004
  scheduler_type: ""
  decay_factor: 0.5
  decay_step: -1
evaluation:
  evaluate_after: -1
  every_eval: 1
  print_every: 100
misc:
  dataset: youcook2
  debug: false
  exp_prefix: youcook2/tgn_lgi/LGI
  method_type: tgn_lgi
  num_workers: 4
  print_every: 100
  result_dir: results/youcook2/tgn_lgi/LGI
  tensorboard_dir: tensorboard/youcoo2/tgn_lgi/LGI
  vis_every: 1
logging:
  print_level: "DEBUG"
  write_level: "INFO"
